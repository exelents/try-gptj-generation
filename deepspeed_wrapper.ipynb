{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f19ef5b",
   "metadata": {},
   "source": [
    "# Prepare requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install zstd\n",
    "\n",
    "# the \"slim\" version contain only bf16 weights and no optimizer parameters, which minimizes bandwidth and memory\n",
    "!time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
    "\n",
    "!time tar -I zstd -xf step_383500_slim.tar.zstd\n",
    "\n",
    "!git clone https://github.com/kingoflolz/mesh-transformer-jax.git\n",
    "!pip install -r mesh-transformer-jax/requirements.txt\n",
    "\n",
    "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
    "!pip install mesh-transformer-jax/ jax==0.2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec10c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/finetuneanon/transformers\n",
    "!git -C ./transformers checkout gpt-j\n",
    "!pip install transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./conv.py  # if you get OOM error try convlowmem.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc6720",
   "metadata": {},
   "source": [
    "# Generetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gptj_wrapper as gptj\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gptj.GPTJ(stage=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76650159",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_newline = model.tokenizer(\"<|endoftext|>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text = \"\"\"I am a highly intelligent question answering bot. If you provide me a context and ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer based on the context, I will respond with \"Unknown\".\n",
    "\n",
    "Context: In 2017, U.S. life expectancy was 78.6 years.\n",
    "Question: What is human life expectancy in the United States?\n",
    "Answer: 78 years.\n",
    "\n",
    "Context: puppy A is happy. puppy B is sad.\n",
    "Question: which puppy is happy?\n",
    "Answer: puppy A.\n",
    "\n",
    "Context: You poured a glass of cranberry, but then absentmindedly, you poured about a teaspoon of grape juice into it. It looks OK. You try sniffing it, but you have a bad cold, so you can't smell anything. You are very thirsty. So you drink it.\n",
    "Question: What happens next?\n",
    "Answer:\n",
    "\"\"\"\n",
    "    start = datetime.datetime.now()\n",
    "    out = model.generate(\n",
    "        text=text,\n",
    "        max_length=512,\n",
    "#         num_beams=5,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_k=5,\n",
    "        top_p=0.9,\n",
    "        no_repeat_ngram_size=2, \n",
    "        early_stopping=True,\n",
    "#         num_return_sequences=1,\n",
    "        use_cache=False,\n",
    "        eos_token_id=eos_newline\n",
    "    )\n",
    "    duration = datetime.datetime.now() - start\n",
    "    for o in out:\n",
    "        print(\"\\n\\n\\n\")\n",
    "        print(o[len(text):])\n",
    "    print(f\"\\n\\nDuration = {duration.total_seconds()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519bcded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
